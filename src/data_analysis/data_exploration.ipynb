{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from pathlib import Path\n",
    "HOME = os.getcwd()\n",
    "DATA_FOLDER = os.path.join(Path(HOME).parent, 'data')\n",
    "data_path = os.path.join(DATA_FOLDER, 'filtered.tsv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reference</th>\n",
       "      <th>translation</th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>ref_tox</th>\n",
       "      <th>trn_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>0.014195</td>\n",
       "      <td>0.981983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.065473</td>\n",
       "      <td>0.999039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>0.213313</td>\n",
       "      <td>0.985068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.053362</td>\n",
       "      <td>0.994215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.009402</td>\n",
       "      <td>0.999348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I'm not gonna have a child... ...with the same...</td>\n",
       "      <td>I'm not going to breed kids with a genetic dis...</td>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>0.950956</td>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>They're all laughing at us, so we'll kick your...</td>\n",
       "      <td>they're laughing at us. We'll show you.</td>\n",
       "      <td>0.618866</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Maine was very short on black people back then.</td>\n",
       "      <td>there wasn't much black in Maine then.</td>\n",
       "      <td>0.720482</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.148710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Briggs, what the hell's happening?</td>\n",
       "      <td>Briggs, what the hell is going on?</td>\n",
       "      <td>0.920373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.159096</td>\n",
       "      <td>0.841071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Another one simply had no clue what to do, so ...</td>\n",
       "      <td>another simply didn't know what to do, so when...</td>\n",
       "      <td>0.877540</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>0.055371</td>\n",
       "      <td>0.930472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I suppose you want me to buy you flowers and c...</td>\n",
       "      <td>you'd probably want me to buy you some chocola...</td>\n",
       "      <td>0.800661</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.980341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>So now their spirits are cursed, walking back ...</td>\n",
       "      <td>their souls are cursed, they guard the paths, ...</td>\n",
       "      <td>0.755883</td>\n",
       "      <td>0.013245</td>\n",
       "      <td>0.842509</td>\n",
       "      <td>0.143992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Freezing him.</td>\n",
       "      <td>I'll freeze him!</td>\n",
       "      <td>0.775646</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.007186</td>\n",
       "      <td>0.573710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Come on, Cal, leave that shit alone.</td>\n",
       "      <td>come on, Cal, put it down.</td>\n",
       "      <td>0.660481</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.999637</td>\n",
       "      <td>0.000279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>So he's the Top dog.</td>\n",
       "      <td>he's the tallest son of a bitch.</td>\n",
       "      <td>0.611092</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000920</td>\n",
       "      <td>0.999639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>I swore when I went out with Xander Harris... ...</td>\n",
       "      <td>when I was dating Alex Harris, I swore I'd rat...</td>\n",
       "      <td>0.790565</td>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.011613</td>\n",
       "      <td>0.996266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I'm famous, and you're done.</td>\n",
       "      <td>I'm famous, and you're dead.</td>\n",
       "      <td>0.817253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.979738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>To quote Jake Oppenheimer: I, who am about to ...</td>\n",
       "      <td>to quote Jake and Oppenheimer: \"I must die, I ...</td>\n",
       "      <td>0.699590</td>\n",
       "      <td>0.178947</td>\n",
       "      <td>0.002348</td>\n",
       "      <td>0.682655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>“Could you please be quiet, Miss Lavish?” said...</td>\n",
       "      <td>'could you keep your mouth shut, Miss Opulent?...</td>\n",
       "      <td>0.808943</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.760356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Murder for hire.</td>\n",
       "      <td>murder to order.</td>\n",
       "      <td>0.697667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074589</td>\n",
       "      <td>0.962326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            reference  \\\n",
       "0   If Alkar is flooding her with psychic waste, t...   \n",
       "1                           Now you're getting nasty.   \n",
       "2            Well, we could spare your life, for one.   \n",
       "3           Ah! Monkey, you've got to snap out of it.   \n",
       "4                    I've got orders to put her down.   \n",
       "5   I'm not gonna have a child... ...with the same...   \n",
       "6   They're all laughing at us, so we'll kick your...   \n",
       "7     Maine was very short on black people back then.   \n",
       "8                  Briggs, what the hell's happening?   \n",
       "9   Another one simply had no clue what to do, so ...   \n",
       "10  I suppose you want me to buy you flowers and c...   \n",
       "11  So now their spirits are cursed, walking back ...   \n",
       "12                                      Freezing him.   \n",
       "13               Come on, Cal, leave that shit alone.   \n",
       "14                               So he's the Top dog.   \n",
       "15  I swore when I went out with Xander Harris... ...   \n",
       "16                       I'm famous, and you're done.   \n",
       "17  To quote Jake Oppenheimer: I, who am about to ...   \n",
       "18  “Could you please be quiet, Miss Lavish?” said...   \n",
       "19                                   Murder for hire.   \n",
       "\n",
       "                                          translation  similarity  \\\n",
       "0   if Alkar floods her with her mental waste, it ...    0.785171   \n",
       "1                         you're becoming disgusting.    0.749687   \n",
       "2                       well, we can spare your life.    0.919051   \n",
       "3                        monkey, you have to wake up.    0.664333   \n",
       "4                          I have orders to kill her.    0.726639   \n",
       "5   I'm not going to breed kids with a genetic dis...    0.703185   \n",
       "6             they're laughing at us. We'll show you.    0.618866   \n",
       "7              there wasn't much black in Maine then.    0.720482   \n",
       "8                  Briggs, what the hell is going on?    0.920373   \n",
       "9   another simply didn't know what to do, so when...    0.877540   \n",
       "10  you'd probably want me to buy you some chocola...    0.800661   \n",
       "11  their souls are cursed, they guard the paths, ...    0.755883   \n",
       "12                                   I'll freeze him!    0.775646   \n",
       "13                         come on, Cal, put it down.    0.660481   \n",
       "14                   he's the tallest son of a bitch.    0.611092   \n",
       "15  when I was dating Alex Harris, I swore I'd rat...    0.790565   \n",
       "16                       I'm famous, and you're dead.    0.817253   \n",
       "17  to quote Jake and Oppenheimer: \"I must die, I ...    0.699590   \n",
       "18  'could you keep your mouth shut, Miss Opulent?...    0.808943   \n",
       "19                                   murder to order.    0.697667   \n",
       "\n",
       "    lenght_diff   ref_tox   trn_tox  \n",
       "0      0.010309  0.014195  0.981983  \n",
       "1      0.071429  0.065473  0.999039  \n",
       "2      0.268293  0.213313  0.985068  \n",
       "3      0.309524  0.053362  0.994215  \n",
       "4      0.181818  0.009402  0.999348  \n",
       "5      0.206522  0.950956  0.035846  \n",
       "6      0.230769  0.999492  0.000131  \n",
       "7      0.187500  0.963680  0.148710  \n",
       "8      0.000000  0.159096  0.841071  \n",
       "9      0.101695  0.055371  0.930472  \n",
       "10     0.160000  0.000078  0.980341  \n",
       "11     0.013245  0.842509  0.143992  \n",
       "12     0.176471  0.007186  0.573710  \n",
       "13     0.270270  0.999637  0.000279  \n",
       "14     0.363636  0.000920  0.999639  \n",
       "15     0.148936  0.011613  0.996266  \n",
       "16     0.000000  0.000926  0.979738  \n",
       "17     0.178947  0.002348  0.682655  \n",
       "18     0.100000  0.000187  0.760356  \n",
       "19     0.000000  0.074589  0.962326  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(data_path, index_col=0, sep='\\t')\n",
    "df.head(20)\n",
    "# data loaded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "current = HOME \n",
    "while 'src' not in os.listdir(current):\n",
    "    current = Path(current).parent\n",
    "\n",
    "sys.path.append(str(current))\n",
    "sys.path.append(os.path.join(str(current), 'data_analysis'))\n",
    "sys.path.append(os.path.join(str(current), 'evaluation'))\n",
    "sys.path.append(os.path.join(str(current), 'text_processing'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial remarks\n",
    "The very first rows in the dataframe display an unexpected behavior: According to the task definition, detoxification is to transfer sentences from toxic to non-toxic under the condition of preserving the semantic meaning. Nevertheless, certain 'translation' sentences are associated with higher toxicity than their 'reference'. Such issue can be fixed pretty easily "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>similarity</th>\n",
       "      <th>lenght_diff</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>source_tox</th>\n",
       "      <th>target_tox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.785171</td>\n",
       "      <td>0.010309</td>\n",
       "      <td>if Alkar floods her with her mental waste, it ...</td>\n",
       "      <td>If Alkar is flooding her with psychic waste, t...</td>\n",
       "      <td>0.981983</td>\n",
       "      <td>0.014195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.749687</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>you're becoming disgusting.</td>\n",
       "      <td>Now you're getting nasty.</td>\n",
       "      <td>0.999039</td>\n",
       "      <td>0.065473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.919051</td>\n",
       "      <td>0.268293</td>\n",
       "      <td>well, we can spare your life.</td>\n",
       "      <td>Well, we could spare your life, for one.</td>\n",
       "      <td>0.985068</td>\n",
       "      <td>0.213313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.664333</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>monkey, you have to wake up.</td>\n",
       "      <td>Ah! Monkey, you've got to snap out of it.</td>\n",
       "      <td>0.994215</td>\n",
       "      <td>0.053362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.726639</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>I have orders to kill her.</td>\n",
       "      <td>I've got orders to put her down.</td>\n",
       "      <td>0.999348</td>\n",
       "      <td>0.009402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.703185</td>\n",
       "      <td>0.206522</td>\n",
       "      <td>I'm not gonna have a child... ...with the same...</td>\n",
       "      <td>I'm not going to breed kids with a genetic dis...</td>\n",
       "      <td>0.950956</td>\n",
       "      <td>0.035846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.618866</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>They're all laughing at us, so we'll kick your...</td>\n",
       "      <td>they're laughing at us. We'll show you.</td>\n",
       "      <td>0.999492</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.720482</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>Maine was very short on black people back then.</td>\n",
       "      <td>there wasn't much black in Maine then.</td>\n",
       "      <td>0.963680</td>\n",
       "      <td>0.148710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.920373</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Briggs, what the hell is going on?</td>\n",
       "      <td>Briggs, what the hell's happening?</td>\n",
       "      <td>0.841071</td>\n",
       "      <td>0.159096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.877540</td>\n",
       "      <td>0.101695</td>\n",
       "      <td>another simply didn't know what to do, so when...</td>\n",
       "      <td>Another one simply had no clue what to do, so ...</td>\n",
       "      <td>0.930472</td>\n",
       "      <td>0.055371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   similarity  lenght_diff                                             source  \\\n",
       "0    0.785171     0.010309  if Alkar floods her with her mental waste, it ...   \n",
       "1    0.749687     0.071429                        you're becoming disgusting.   \n",
       "2    0.919051     0.268293                      well, we can spare your life.   \n",
       "3    0.664333     0.309524                       monkey, you have to wake up.   \n",
       "4    0.726639     0.181818                         I have orders to kill her.   \n",
       "5    0.703185     0.206522  I'm not gonna have a child... ...with the same...   \n",
       "6    0.618866     0.230769  They're all laughing at us, so we'll kick your...   \n",
       "7    0.720482     0.187500    Maine was very short on black people back then.   \n",
       "8    0.920373     0.000000                 Briggs, what the hell is going on?   \n",
       "9    0.877540     0.101695  another simply didn't know what to do, so when...   \n",
       "\n",
       "                                              target  source_tox  target_tox  \n",
       "0  If Alkar is flooding her with psychic waste, t...    0.981983    0.014195  \n",
       "1                          Now you're getting nasty.    0.999039    0.065473  \n",
       "2           Well, we could spare your life, for one.    0.985068    0.213313  \n",
       "3          Ah! Monkey, you've got to snap out of it.    0.994215    0.053362  \n",
       "4                   I've got orders to put her down.    0.999348    0.009402  \n",
       "5  I'm not going to breed kids with a genetic dis...    0.950956    0.035846  \n",
       "6            they're laughing at us. We'll show you.    0.999492    0.000131  \n",
       "7             there wasn't much black in Maine then.    0.963680    0.148710  \n",
       "8                 Briggs, what the hell's happening?    0.841071    0.159096  \n",
       "9  Another one simply had no clue what to do, so ...    0.930472    0.055371  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# fix the order\n",
    "def fix_order_map(row):\n",
    "    row['source'], row['target'] = (row['reference'], row['translation']) if row['ref_tox'] > row['trn_tox'] else (row['translation'], row['reference'])\n",
    "    row['source_tox'], row['target_tox'] = (row['ref_tox'], row['trn_tox']) if row['ref_tox'] > row['trn_tox'] else (row['trn_tox'], row['ref_tox'])\n",
    "    return row\n",
    "\n",
    "# df_fixed = df.apply(fix_order_map, axis=1)\n",
    "# df_fixed.drop(columns=['translation', 'reference', 'ref_tox', 'trn_tox'], inplace=True)\n",
    "# assert np.all(df_fixed['source_tox'] > df_fixed['target_tox'])\n",
    "# df_fixed.to_csv(os.path.join(DATA_FOLDER, 'fixed.csv'), index=False, sep=',')\n",
    "\n",
    "df = pd.read_csv(os.path.join(DATA_FOLDER, 'fixed.csv'), sep=',')\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarization: A possible Direction\n",
    "Besides the minor issues with the data, the few examples displayed above exhibit an interesting behavior: 'target' sentences tend to be shorted (both in number of characters and words / tokens in general). Thus, one possible hypothesis to formualize is the following: \n",
    "\n",
    "<p align=\"center\">\n",
    "Concise sentences tend to be less toxic than the lengthy ones\n",
    "</p>\n",
    "\n",
    "We will consider the following statistics for each type of sentences:\n",
    "1. Number of stop words\n",
    "2. The portion of stop word-like tokens out of all tokens\n",
    "3. The averge length of a non-stop word  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since most sentences are not too long, we will use the standard list of stop words in the 'english' language.\n",
    "from src.text_processing import preprocess as pr\n",
    "import importlib\n",
    "importlib.reload(pr)\n",
    "STOP_WORDS = pr.standard_stop_words()\n",
    " \n",
    "def process(text: str) -> str:\n",
    "    # first lower text\n",
    "    text = pr.no_extra_spaces(pr.no_extra_chars(pr.to_lower(text)))\n",
    "    # # lemmatize and tokenize \n",
    "    ts = pr.tokenize(text, 'word')\n",
    "    res = pr.lemmatize(ts)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the processing function seems to work as intended. Now, we need to write a function to estimate the different statistics for each sentence.\n",
    "\n",
    "def stats_gen(df: pd.DataFrame):\n",
    "    # iterate through row in the dataframe:\n",
    "    for _, row in df.iterrows():\n",
    "        # first process each of the sentences \n",
    "        target = process(row['target'])\n",
    "        source = process(row['source']) \n",
    "\n",
    "        target_relevant = [t for t in target if t not in STOP_WORDS]\n",
    "        source_relevant = [t for t in source if t not in STOP_WORDS]\n",
    "        \n",
    "        target_num_stop = len(target) - len(target_relevant)\n",
    "        source_num_stop = len(source) - len(source_relevant)    \n",
    "\n",
    "        # calculate the portion of stop words in each sentence\n",
    "        target_stop_portion = round((target_num_stop / len(target)) if len(target) > 0 else 1, 4)\n",
    "        source_stop_portion = round((source_num_stop / len(source)) if len(source) > 0 else 1, 4)\n",
    "\n",
    "        # calculate the average word's length for each sentence \n",
    "        target_w_len = round((len(\" \".join(target_relevant)) / len(target_relevant)) if len(target_relevant) > 0 else 0, 3)\n",
    "        source_w_len = round((len(\" \".join(source_relevant)) / len(source_relevant)) if len(source_relevant) > 0 else 0, 3)\n",
    "\n",
    "        yield {\"source_non_stop\": len(source_relevant), \n",
    "               \"target_non_stop\": len(target_relevant), \n",
    "               \n",
    "               \"source_stop\": source_num_stop,\n",
    "               \"target_stop\": target_num_stop,\n",
    "               \n",
    "               \"source_stop_portion\": source_stop_portion, \n",
    "               \"target_stop_portion\": target_stop_portion, \n",
    "\n",
    "               \"source_word_len\": source_w_len, \n",
    "               \"target_word_len\": target_w_len}\n",
    "        \n",
    "# create a dataframe \n",
    "stats_df = pd.DataFrame(data=stats_gen(df))\n",
    "# save the dataframe\n",
    "stats_df.to_csv(os.path.join(DATA_FOLDER, 'summary_stats.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_non_stop</th>\n",
       "      <th>target_non_stop</th>\n",
       "      <th>source_stop</th>\n",
       "      <th>target_stop</th>\n",
       "      <th>source_stop_portion</th>\n",
       "      <th>target_stop_portion</th>\n",
       "      <th>source_word_len</th>\n",
       "      <th>target_word_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.4118</td>\n",
       "      <td>6.364</td>\n",
       "      <td>6.900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>6.250</td>\n",
       "      <td>4.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3750</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>3.800</td>\n",
       "      <td>3.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3846</td>\n",
       "      <td>3.750</td>\n",
       "      <td>3.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>4.000</td>\n",
       "      <td>3.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>4.133</td>\n",
       "      <td>5.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.3636</td>\n",
       "      <td>3.857</td>\n",
       "      <td>3.857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>4.857</td>\n",
       "      <td>4.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.2857</td>\n",
       "      <td>4.750</td>\n",
       "      <td>5.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>0.4800</td>\n",
       "      <td>0.5172</td>\n",
       "      <td>5.154</td>\n",
       "      <td>4.786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>0.4211</td>\n",
       "      <td>0.4375</td>\n",
       "      <td>6.182</td>\n",
       "      <td>6.333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4242</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>4.842</td>\n",
       "      <td>4.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>4.000</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.2000</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>3.875</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.4444</td>\n",
       "      <td>0.4286</td>\n",
       "      <td>4.400</td>\n",
       "      <td>3.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>4.500</td>\n",
       "      <td>5.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>3.667</td>\n",
       "      <td>3.667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>0.3810</td>\n",
       "      <td>5.000</td>\n",
       "      <td>5.231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.1667</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>5.100</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>4.667</td>\n",
       "      <td>4.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    source_non_stop  target_non_stop  source_stop  target_stop  \\\n",
       "0                11               10            7            7   \n",
       "1                 4                4            1            2   \n",
       "2                 5                8            3            3   \n",
       "3                 4                8            4            5   \n",
       "4                 3                5            4            4   \n",
       "5                15                9           10            7   \n",
       "6                 7                7            7            4   \n",
       "7                 7                6            3            3   \n",
       "8                 4                5            4            2   \n",
       "9                13               14           12           15   \n",
       "10               11                9            8            7   \n",
       "11               19               18           14           16   \n",
       "12                3                2            2            1   \n",
       "13                8                6            2            3   \n",
       "14                5                4            4            3   \n",
       "15               12               12            8            8   \n",
       "16                6                6            3            3   \n",
       "17               13               13            5            8   \n",
       "18               10                9            2            2   \n",
       "19                3                3            1            1   \n",
       "\n",
       "    source_stop_portion  target_stop_portion  source_word_len  target_word_len  \n",
       "0                0.3889               0.4118            6.364            6.900  \n",
       "1                0.2000               0.3333            6.250            4.750  \n",
       "2                0.3750               0.2727            3.800            3.875  \n",
       "3                0.5000               0.3846            3.750            3.500  \n",
       "4                0.5714               0.4444            4.000            3.800  \n",
       "5                0.4000               0.4375            4.133            5.111  \n",
       "6                0.5000               0.3636            3.857            3.857  \n",
       "7                0.3000               0.3333            4.857            4.167  \n",
       "8                0.5000               0.2857            4.750            5.200  \n",
       "9                0.4800               0.5172            5.154            4.786  \n",
       "10               0.4211               0.4375            6.182            6.333  \n",
       "11               0.4242               0.4706            4.842            4.833  \n",
       "12               0.4000               0.3333            4.000            5.000  \n",
       "13               0.2000               0.3333            3.875            3.000  \n",
       "14               0.4444               0.4286            4.400            3.000  \n",
       "15               0.4000               0.4000            4.500            5.500  \n",
       "16               0.3333               0.3333            3.667            3.667  \n",
       "17               0.2778               0.3810            5.000            5.231  \n",
       "18               0.1667               0.1818            5.100            5.000  \n",
       "19               0.2500               0.2500            4.667            4.333  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization and Statistics Make sure the results are promising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create the summarized dataset: show that the current results lead to a decrease of toxicity: suggesting that introducing toxicity into training might indeed lead to decent results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 2 different ways to do that: \n",
    "1. Either introduce a loxiticity loss to the model\n",
    "    * introduce the loss from the toxic evaluaton as it is directly\n",
    "    * evaluate the toxicity of each word / tuple statistically.\n",
    "2. Use a Masked Language model \n",
    "3. Find a way to simply replace synonyms, then teach a model to convert lemmatized models to their original state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
