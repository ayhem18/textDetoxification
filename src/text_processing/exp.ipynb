{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "strings = [\"South Korea is a great country !!\", \"Nelson Bush was a great friend.\"]\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp.component_names\n",
    "p1 = nlp.pipe(texts=strings, disable=['lemmatizer', 'attribute_ruler', 'senter'])\n",
    "p2 = nlp.pipe(texts=strings, disable=['tagger', 'attribute_ruler', 'senter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Iterable, List, Dict\n",
    "from collections import defaultdict\n",
    "\n",
    "spacy_labels = {\"NORP\": \"group\", \"ORG\": \"organization\", \"GPE\": \"location\", \"LOC\": \"location\", \"WORK_OF_ART\": \"art\", \"FAC\": \"facility\"}\n",
    "\n",
    "def _uniform_ne(doc_obj, label_name_map: Dict):\n",
    "    last_ne = None\n",
    "    tokens = []\n",
    "    for t in doc_obj:\n",
    "        if t.ent_type != 0:\n",
    "            if last_ne is None or last_ne != t.ent_type:\n",
    "                # append label in this case, make sure the useful name is passed\n",
    "                tokens.append((label_name_map[t.ent_type_] if (t.ent_type_ in label_name_map) else t.ent_type_))\n",
    "                # tokens.append(t.ent_type_)\n",
    "        else:\n",
    "            tokens.append(t.text)\n",
    "        last_ne = t.ent_type\n",
    "        \n",
    "    return \" \".join(tokens)        \n",
    "\n",
    "def uniform_ne_batched(strings: Iterable[str], nlp = None) -> Iterable[str]:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")  \n",
    "    # create the pipeline: only keeps components relevant to NER\n",
    "    pipe = nlp.pipe(texts=strings, disable=['tagger', 'attribute_ruler', 'senter'], )\n",
    "    \n",
    "    return [_uniform_ne(doc, spacy_labels) for doc in pipe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "strings = ['George Bush has been my friend since I met him in South Korea', \n",
    "           \"Well, I won't forget the day I saw Maria playing tennis for 10 millions in Cuba.\", \n",
    "           \"English is hard to learn\",\n",
    "           \"The only woman more beautiful than Daria Farlov is Sarah Smith.\", \n",
    "           \"The first time I saw Mark was in Japan befor Cuba.\"]\n",
    "\n",
    "s = uniform_ne_batched(strings)\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
